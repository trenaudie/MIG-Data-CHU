{"cells":[{"cell_type":"markdown","metadata":{"id":"eWlxgPwnThIT"},"source":["## Importations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpzc3kaeThIb"},"outputs":[],"source":["#basic imports\n","import pandas as pd\n","import numpy as np \n","import itertools\n","from typing import List\n","import matplotlib.pyplot as plt\n","import os\n","from random import shuffle, sample\n","import warnings\n","from tqdm import tqdm\n","\n","#smoothing and gapfilling\n","from scipy.signal import convolve, hamming\n","\n","#fourier features\n","from scipy import signal as sg\n","#wavelets features\n","import pywt\n","import scipy as sc\n","\n","#pca\n","from sklearn import decomposition , metrics\n","\n","#classifiers\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"markdown","metadata":{"id":"cHlXNLZcThIe"},"source":["## Cleaning the data"]},{"cell_type":"markdown","metadata":{"id":"kMAlsR0BThIe"},"source":["The first step of our project is to turn surgery records into patients records with usable data. During surgery, the priority isn't the recording, some sensors are therefore often not recording or giving false values. The main goal here is to summarize all pieces of data into understandable signals."]},{"cell_type":"markdown","metadata":{"id":"orDYAfcHThIf"},"source":["### Mapping\n","\n","If your data isn't recorded similarly as ours, you can change the columns names in the following cell (lists below): the first sensor is the most reliable and the last the less reliable.\n","\n","FC stands for heart frequency, Pouls for heart frequency calculated with the pulse oxymetry sensor for example\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXWHgcoPThIg"},"outputs":[],"source":["blood_pressure_sensors = [\"PAm\", \"PNIm\", \"PBm\"]\n","temperature_sensors = [\"Temp\", \"Toeso\", \"T1\"]\n","heart_freq_sensors = ['FC', 'Pouls']\n","already_used = ['HEURE','DATE','LIT','NOM']  + blood_pressure_sensors + temperature_sensors + heart_freq_sensors"]},{"cell_type":"markdown","metadata":{"id":"BzHEJ92DThIh"},"source":["A lot of sensors are used during surgery, with some of them recording the same thing. The following functions gather all columns and give priority to most reliable sensors for each feature(temperature, heart frequency, blood oxygenation...)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQ3hoFFLThIh"},"outputs":[],"source":["def get_pulses(df):\n","    \"\"\"Returns a pandas series filled with blood pressure from df.FC or df.Pouls if the latter is unavailable.\n","    Args:\n","        - df : pandas.DataFrame  -> df[\"FC\"]\n","    Returns:\n","        - pandas.Series\n","    \"\"\"\n","    serie_pulses  = df[heart_freq_sensors[0]].copy()\n","    for sensor in heart_freq_sensors[1:]:\n","        serie_pulses.loc[serie_pulses.isna()] = df[sensor].loc[serie_pulses.isna()]\n","\n","    return serie_pulses\n","    \n","def get_blood_pressure(df):\n","    \"\"\"Returns a pandas series filled with blood pressure from df['PAm'], df['PNIm'] if the latter is unavailable or df['PBm'] as a last resort\n","    \"\"\"\n","    \n","    serie_blood_pressure = df[blood_pressure_sensors[0]].copy()\n","    for sensor in blood_pressure_sensors[1:]:\n","        serie_blood_pressure.loc[serie_blood_pressure.isna()] = df[sensor].loc[serie_blood_pressure.isna()]\n","\n","    return serie_blood_pressure\n","\n","\n","def get_temperature(df):\n","    \"\"\"Returns a pandas series filled with temperature from df['Temp'], df['Toeso'] if the latter is unavailable or df['T1'] as a last resort\n","    \"\"\"\n","\n","    serie_temperature = df[temperature_sensors[0]].copy()\n","    for sensor in temperature_sensors[1:]:\n","        serie_temperature.loc[serie_temperature.isna()] = df[sensor].loc[serie_temperature.isna()]\n","\n","    return serie_temperature"]},{"cell_type":"markdown","metadata":{"id":"qq4gZoP7ThIj"},"source":["The mapping function creates the *clean* Dataframe of a patient. In our case, the operating room number 4 is dedicated to heart surgery. For the other operating rooms, we chose to only keep heart frequency, body temperature and blood oxygenation, because other vital signs were not recorded for most patients. Surgeries occuring in the operating room number 4 are much different from the other ones, and provide a lot more vital signs, which led us to handle this room differently when it comes to mapping, and later to phase it out of the prediction process."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1COdOfcThIj"},"outputs":[],"source":["def mapping(df, bloc_4 = False):\n","    \"\"\"Returns a Dataframe containing the heart frequency, blood pressure, SpO2, respiratory rate and temperature except for the operating room number 4.\n","    \"\"\"\n","    df.replace('AP', np.NaN, inplace = True)\n","    mapped_df = pd.DataFrame()\n","    mapped_df[\"seconde\"] = df[\"seconde\"].copy()\n","    mapped_df[\"Pouls\"] = get_pulses(df)\n","    mapped_df[\"Pression\"] = get_blood_pressure(df)\n","    if not bloc_4:\n","        mapped_df[\"Temperature\"] = get_temperature(df)\n","        mapped_df[\"SpO2\"] = df[\"SpO2\"].copy()\n","        mapped_df[\"FR\"] = df[\"FR\"].copy()\n","    else :\n","    #adding other sensors specific to bloc 4 \n","        mapped_df = pd.concat([mapped_df, pd.concat([df[col] for col in df.columns.drop(already_used)], axis=1)], axis=1)\n","    \n","        \n","    mapped_df.dropna(axis = 1, how = 'all')\n","    \n","    return mapped_df.astype(float)"]},{"cell_type":"markdown","metadata":{"id":"_HtRrX3jThIl"},"source":["### Splitting patients\n","\n","The main idea here is to identify and separate each patient in every operation file, which often consists in 2 or 3 days of continuous recording. Of course, sensors might stop recording for several minutes in the middle of an operation, or on the contrary record for a few seconds during a break."]},{"cell_type":"markdown","metadata":{"id":"AcB9qWz5ThIl"},"source":["<figure ><figcaption >Identifying different patients in the data:</figcaption><video src=\"split_video.mp4\" width=80% autoplay loop>  </video> </figure>"]},{"cell_type":"markdown","metadata":{"id":"qsHDTDcPThIm"},"source":["The first step is to create a pandaSeries that summarizes the heart rate, blood oxygenation, blood pressure and respiration rate, considering that the recording of one of those vital signs is equivalent to having a patient in the operating room. This Serie hasn't any medical meaning but is a timeline of the global recorded data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeGwcA4HThIn"},"outputs":[],"source":["def column_test_patient(df):\n","    '''\n","    arg: df, DataFrame\n","    return: DataSerie of meaningful Series\n","    '''\n","    serie_patient = df['Pouls'].copy()\n","    serie_patient[serie_patient.isna()] = df['SpO2'].loc[serie_patient.isna()]\n","    serie_patient[serie_patient.isna()] = df['Pression'].loc[serie_patient.isna()]\n","    serie_patient[serie_patient.isna()] = df['FR'].loc[serie_patient.isna()]\n","\n","    return serie_patient"]},{"cell_type":"markdown","metadata":{"id":"M1hpCLITThIp"},"source":["We then turn this timeline into a binary information (is the data recorded or not?)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVHzGpxgThIp"},"outputs":[],"source":["def binar_list(df):\n","    '''\n","    arg: df, DataFrame\n","    return: binary mask (list) indicating the presence of data with 1, absence by 0.\n","    '''\n","    patient_serie=column_test_patient(df)\n","    return patient_serie.notna().astype(int)\n"]},{"cell_type":"markdown","metadata":{"id":"0eaMcPGbThIq"},"source":["The following function summarizes the information of the previous timeline, by giving the length of each sequence, which will enable us to decide whether a sequence of missing datas can be interpreted as a change of patient."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzyBMEczThIr"},"outputs":[],"source":["def list_index_patients(binar_list):\n","    '''\n","    arg: binar_list\n","    return: list of tuple (key,length of sequence)\n","    '''\n","    return [\n","        (key, len(list(group))) \n","        for key, group in itertools.groupby(binar_list)\n","    ]\n"]},{"cell_type":"markdown","metadata":{"id":"q4XgZbx7ThIs"},"source":["We had some difficulties to seperate patients because of the noise (sensors recording during a break). The following handles this issue by deleting the noise (in fact gathering the two break sequences that were artificially splitted because of this wrong value)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6PL8HtJ6ThIs"},"outputs":[],"source":["def noises_treatment(list_index_patient, threshold):\n","    '''\n","    arg: list of tuples (key,length of sequence), threshold (duration of bloc cleaning)\n","    return: list of tuples (key,length of sequence) without noise\n","    '''\n","    new_index = [list_index_patient[0]]\n","    i = 1\n","    while i <(len(list_index_patient)-1):\n","        if list_index_patient[i][1]<threshold:\n","            last_el = list(new_index[-1])\n","            last_el[1] += list_index_patient[i][1]\n","            last_el[1] += list_index_patient[i+1][1]\n","            new_index[-1] = tuple(last_el)\n","            i += 1\n","        else :\n","            new_index.append(list_index_patient[i])\n","        i += 1\n","    if list_index_patient[-1][1]>=threshold :\n","        new_index.append(list_index_patient[-1])\n","    else : \n","        last_el = list(new_index[-1])\n","        last_el[1] += list_index_patient[-1][1]\n","        new_index[-1] = tuple(last_el)\n","    return new_index"]},{"cell_type":"markdown","metadata":{"id":"M1sp6cIXThIt"},"source":["We then have to identify the beginning and the end of every surgery. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h0gkQUkgThIu"},"outputs":[],"source":["def accumulate_list(list_len):\n","    return [0]+list(itertools.accumulate(list_len))\n","\n","def break_finder(list_index_patients, threshold):\n","    '''\n","    arg: list of tuples (key,length of sequence) without noise\n","    return: list of lists [begin,end] which frame the sequences of cleaning\n","    '''\n","    list_len = [len1[1] for len1 in list_index_patients]\n","    accumulate_list1 = accumulate_list(list_len)\n","    breaks = []\n","    for index,len1 in enumerate(list_index_patients):\n","        value, length = len1\n","        begin, end = accumulate_list1[index] , accumulate_list1[index+1]\n","        if (value == 0) and (length > threshold):\n","            breaks.append([begin,end])\n","    return breaks"]},{"cell_type":"markdown","metadata":{"id":"6k1QgTKqThIu"},"source":["Finally we can slice the data into patients."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9GbSh9CThIv"},"outputs":[],"source":["def list_to_patients(list_break,df):\n","    \"\"\"takes a list of lists [begin,end] and the corresponding dataframe and returns a list containing one Dataframe for each patient.\n","    Args:\n","        - list_break: list\n","        - df: pd.DataFrame\n","    Return\n","        patients: list of pd.Dataframes\"\"\"\n","    patients=[df[list_break[i][1]:list_break[i+1][0]] for i in range (-1,len(list_break)-1)] #On commence à -1 pour réserver une case pour le potentiel premier patient\n","    if list_break:\n","        patients[0]=df[0:list_break[0][0]]\n","        patients.append(df[list_break[-1][1]:-1])\n","    return patients\n","\n","\n","def separation_patients(df, threshold):\n","    '''\n","    Args: \n","        - df: Dataframe ; \n","        - threshold: int (duration of bloc cleaning)\n","    returns: list of patients' DataFrames\n","    '''\n","    list_index_patients1 = list_index_patients(binar_list(df))\n","    list_index_pat_treated = noises_treatment(list_index_patients1, threshold)\n","    breaks = break_finder(list_index_pat_treated, threshold)\n","\n","    return list_to_patients(breaks, df)"]},{"cell_type":"markdown","metadata":{"id":"1ULyRJcHThIw"},"source":["### Cleaning the data\n","We then have to delete empty csv files, or patients without a regular time Serie. The following cell deals with these cases."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUWpN_T5ThIw"},"outputs":[],"source":["def second(df):\n","    \"\"\"returns a pandas series containing the time in seconds.\n","    Args: \n","        - df: pandas.DataFrame \n","    Return: \n","        - pandas.Series \"\"\"\n","    delta_serie = pd.to_datetime(df.HEURE) - pd.to_datetime(df.HEURE[0])\n","    delta_serie = delta_serie.apply(lambda delta : delta.total_seconds())\n","    \n","    while (delta_serie<0).any() :\n","        delta_serie.loc[delta_serie<0]+= 60*24*60\n","    \n","    return delta_serie\n","\n","def df_is_empty(df):\n","    '''\n","    Returns True if the Dataframe \"df\" is empty, False if not.\n","    '''\n","    return len(df) < 5\n","\n","def time_is_missing(df):\n","    '''\n","    Returns True if the Dataframe \"df\" has no column containing the time, False if not\n","    '''\n","    return 'HEURE' not in df.columns\n","\n","def patient_is_empty(patient):\n","    '''\n","    Returns True if the surgery lasts less that 20 minutes, False if not.\n","\n","    '''\n","    return len(patient)<4*60"]},{"cell_type":"markdown","metadata":{"id":"oABgUascThIx"},"source":["### Sorting the recording files by time\n","\n","We used this function to sort our csv file by time. This can be useful when the recording of a single patient is splited in two csv files following each other. It is then necessary to detect it and merge the two differents parts of the surgery. This case is not handled in this notebook and can be added if needed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyiUHIbiThIy"},"outputs":[],"source":["def sort_folder(folder):\n","    \"\"\"takes the path to the data as argument and returns a dictionary containing as keys the name of the operating rooms \n","    and as values a list of csv files sorted by date.\n","    Args :\n","        - folder : string (path the the folder containing the data)\n","    Returns :\n","        - dic : dictionary \n","    \"\"\"\n","    sorted_list = [\n","        (filename[0:7] + filename[-8:-4] + filename[-12:-10], filename) \n","        for filename in os.listdir(folder)\n","    ]\n","    sorted_list.sort()\n","    \n","    dic = {}\n","    for string, filename in sorted_list : \n","        key = filename[0:6]\n","        if key not in dic:\n","            dic[key] = []\n","            \n","        dic[filename[0:6]].append(filename)\n","    return dic"]},{"cell_type":"markdown","metadata":{"id":"8tODnR1DThIy"},"source":["### Operating room cleaning duration\n"]},{"cell_type":"markdown","metadata":{"id":"1_xbWIWJThIz"},"source":["This dictionnary represents the shortest duration for switching patients for each operating room. If the data is missing for less than this time span, than we are sure that there was no patient switch during this elapsed time. This duration is different for each operating room because some are dealing with emergencies (operating room number 1), others not.\n","\n","This dictionary can be adapted to all time constraints."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yM3a8p_5ThIz"},"outputs":[],"source":["thresholds = {\n","        'bloc_1':15*60//5,\n","        'bloc_2':20*60//5,\n","        'bloc_3':20*60//5,\n","        'bloc_4':20*60//5,\n","        'bloc_5':20*60//5,\n","        'bloc_6':20*60//5,\n","        'bloc_7':20*60//5,\n","        'bloc_8':20*60//5,\n","        'Bloc_1':15*60//5,\n","        'Bloc_2':20*60//5,\n","        'Bloc_3':20*60//5,\n","        'Bloc_4':20*60//5,\n","        'Bloc_5':20*60//5,\n","        'Bloc_6':20*60//5,\n","        'Bloc_7':20*60//5,\n","        'Bloc_8':20*60//5\n","    }"]},{"cell_type":"markdown","metadata":{"id":"UNqqttjHThI1"},"source":["### Splitting function\n","\n","It's now time to gather everything. This function writes a csv file for every detected patient, in a new folder named \"patients\". Of course, we keep only patients with usable data (where time is not missing for example). To use this function,  give the path to the folder containing the data (csv files with encoding latin-1)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saOb0cXoThI2"},"outputs":[],"source":["def processing(folder):\n","    if not os.path.exists(\"patients\"):\n","        os.makedirs(\"patients\")\n","    dic = sort_folder(folder)\n","    for bloc, filelist in dic.items():\n","        for filename in tqdm(filelist, desc = bloc):\n","            df = pd.read_csv(f\"{folder}/{filename}\", encoding = 'latin-1', low_memory=False)# les 'AP' dans des colonnes de floats créent un warning, ce cas est géré dans mapping(on remplace les 'AP' par des NaN)\n","            if df_is_empty(df) or time_is_missing(df):\n","                continue\n","            df['seconde'] = second(df)\n","            df = mapping(df, bloc_4 = (bloc == \"bloc_4\"))\n","            for ind, patient in enumerate(separation_patients(df,thresholds[bloc])):\n","                patient_name = filename.replace(\".csv\",f\"_{ind}.csv\")\n","                patient_filename = \"patients/\" + patient_name\n","                if patient_is_empty(patient):\n","                    continue\n","                patient.to_csv(patient_filename)"]},{"cell_type":"markdown","metadata":{"id":"kBAuvLnDThI3"},"source":["Here is an example of one of the dataframes written by this function. \n","<img src=\"data_frame_patient.png\"> </img>"]},{"cell_type":"markdown","metadata":{"id":"lRHEbDE_ThI6"},"source":["## Labelling\n"]},{"cell_type":"markdown","metadata":{"id":"JVt3pEP4ThI7"},"source":["This step can't be done in this notebook, labelling has to be done on the user's end. For the next step, a new training folder containing folders named by labels is needed.\n","\n","<img src=\"folder_train_example.png\" width=80%>"]},{"cell_type":"markdown","metadata":{"id":"RbUvznTCThI8"},"source":["The main idea is to identify whether the surgery went without problems, and if not to only keep the part before the heart attack, in order to train the algorithm not to recognize an attack but to anticipate it, as shown in the video below."]},{"cell_type":"markdown","metadata":{"id":"1NP37hrYThI8"},"source":["<video src=\"labelling_video.mp4\" width=80% autoplay loop>  </video>"]},{"cell_type":"markdown","metadata":{"id":"Uaq5tF-jThI9"},"source":["### Examples\n","\n","To be clearer, here are some patients with the labels we gave them, based only on heart rate and blood oxygenation"]},{"cell_type":"markdown","metadata":{"id":"EcD9das8ThI9"},"source":["<figure> <img src=\"clean.png\" width=80%> </img> <figcaption> Clean Patient</figcaption></figure>"]},{"cell_type":"markdown","metadata":{"id":"mU5UK3W5ThI-"},"source":["<figure> <img src=\"anomaly.png\" width=80%> </img> <figcaption> Anomaly Patient</figcaption></figure>"]},{"cell_type":"markdown","metadata":{"id":"uldMThXfThI_"},"source":["<figure> <img src=\"attack.png\" width=80%> </img> <figcaption> Attack Patient</figcaption></figure>"]},{"cell_type":"markdown","metadata":{"id":"zs1fHicCThJA"},"source":["## Patient class"]},{"cell_type":"markdown","metadata":{"id":"VPymYxJRThJB"},"source":["The aim of this class is to simplify the use of the patients' data. It allows for manipulations on the patient's information\n","that are needed before sending it to a classifier with one unique structure. "]},{"cell_type":"markdown","metadata":{"id":"vOL2Qq0NThJB"},"source":["### Cleaning the data\n","Those functions are used in the Patient Class, in order to fill the small gaps, and remove the outliers (sometimes due to wrong mesures or to the surgery directly)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwI6ax1JThJB"},"outputs":[],"source":["def clear_col(file):\n","    #Retire les colonnes vides\n","    res = []\n","    df = pd.read_csv(file, encoding= 'unicode_escape')\n","    for col in df.columns:\n","        if df[col].notna().sum() != 0:\n","            res.append(col)\n","    return res, df\n","\n","def g(x):\n","    '''Auxiliary function used for sorting'''\n","    return 40/x if x > 30 else 2\n","\n","def get_rolling_features(serie, length):\n","    return (\n","        serie.rolling(length).std(),\n","        serie.rolling(length).mean()\n","    )\n","\n","def moy(serie, length):\n","    '''Running average'''\n","    win = hamming(length)\n","    res = serie.copy()\n","    res[2:len(res)-1] = pd.Series(convolve(serie, win/np.sum(win), mode = 'valid'))\n","    return res\n","\n","def intermed(serie, length, index, rl_std, rl_mean, duree_min = 6, window = 13):\n","    '''Auxiliary function used for sorting'''\n","    a = 0 #Compte le nombre de points outlier d'affilés\n","    for i in range(2 * window):\n","        while abs(serie[min(len(serie) -1, index-window+i)] - rl_mean[i]) < g(rl_std[i])*rl_std[i]:\n","            a+=1\n","            i+=1\n","            if a >= duree_min: #C'est la durée à partir duquel on considère que le point n'est pas un outlier\n","                return(serie[min(len(serie) -1, index-window+i)])\n","        a=0\n","    return np.nan\n","\n","def tri(serie, length = 20, j = 2, max_std = 2): #Est censée retirer les valeurs bizarres dues aux erreurs de mesure. On ne l'utilise pas non plus\n","    \"\"\"Gets rid of outliers of the series \"series\" given as an argument.\"\"\"\n","    res = serie.copy()\n","    rl_std, rl_mean = get_rolling_features(serie, length)\n","    for i in range(13, len(serie)-13):\n","        if rl_std[i] <= max_std or abs(serie[i] - rl_mean[i]) < g(rl_std[i])*rl_std[i]:\n","            res[i] = serie[i]\n","        else:     \n","            res[i] = intermed(serie, length, i, rl_std, rl_mean)\n","    return res\n","\n","def lissage(serie):\n","    '''Smooths the serie given as an argument.'''\n","    return moy(serie, 4)\n","\n","def new_series(serie, outlier):\n","    '''A combination of the 2 previous functions. Gets rid of outliers only if \"outlier\" is set to True.'''\n","    if outlier:\n","        return lissage(tri(serie)).interpolate(methode = \"slinear\")\n","    return lissage(serie).interpolate(methode = \"slinear\")\n","\n","def new_series_gap_filling(serie):\n","    return serie.interpolate(methode=\"slinear\")\n"]},{"cell_type":"markdown","metadata":{"id":"aYR5Qk2mThJC"},"source":["### PCA Feature\n","The pca can be considered as a classifier in itself, but we decided to use it as a feature. The following function returns the difference between the real data and the one recreated by the pca. More details on the PCA in our report."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftB9c3NNThJC"},"outputs":[],"source":["def compute_transform_error1(pca, dataset):\n","    dataset_transformed = pca.inverse_transform(\n","        pca.transform(dataset)\n","    )\n","\n","    return np.linalg.norm(\n","        dataset - dataset_transformed,\n","        axis = -1\n","    )"]},{"cell_type":"markdown","metadata":{"id":"N7GsOIrcThJD"},"source":["Here is a description of the properties and methods that compose the Patient class."]},{"cell_type":"markdown","metadata":{"id":"MriEFlhCThJE"},"source":["### Classmethod from_file :  \n","This class method reads a csv file and turns it into a patient object, in which the gap in the patient's data have been filled. "]},{"cell_type":"markdown","metadata":{"id":"c_Owovp0ThJF"},"source":["### Properties\n","The following properties facilitate the acces to the data of a patient: bloc, Pouls, SpO2, temp, Pression, fr, seconds, duree."]},{"cell_type":"markdown","metadata":{"id":"v4uRwLeuThJF"},"source":["### Preparing the data for the features:\n","- gap_filling method: fills all the gap in a patient's data.\n","- smoothing method : smooths a patient's data using a linear approximation.\n","- slicing method:  selects the time span in which a patient's data will be analysed. It is essential because some features as the Fourier transformation require data with similar lengths, but not all operations have the same duration.It also enables to choose wether we include the gap_filling in the patient's informations.\n","- method standard : standardizes a patient's data (sets their mean to zero and their standard deviation to 1)\n","- method center : centers patient's data (sets their mean to zero)"]},{"cell_type":"markdown","metadata":{"id":"GoQqhfNQThJG"},"source":["### Features\n","All the following methods return features:\n","- coefsPouls1_Spo2_0\n","- coefsPouls0_Spo2_0\n","- mcr_spo2_0\n","- mcr_pouls_1\n","- ondelettes_SpO2_Pouls\n","- energy_dwt\n","- moment\n","- corr_P_S_dwt\n","- mean\n","- std\n","- min\n","- max\n","- first quartile\n","- median\n","- third quartile\n","- fourier\n","- pca_error"]},{"cell_type":"markdown","metadata":{"id":"NHm4_kVIThJG"},"source":["### Getting features\n"," This method helps us gather all the feature that we need on a patient. It applies the preceding functions, that calculate features on a patient's data, with the chosen parameters. The results are stored in a pandas DataFrame, where each column is a feature."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8jG1I3YThJH"},"outputs":[],"source":["samplerate =1/5\n","\n","\n","class Patient:\n","    \n","    def __init__(self,name,df, label = None):\n","        self.df = df\n","        self.name = name\n","        self.label = label\n","\n","        \n","    @classmethod\n","    def from_file(cls, filename, path=\"\", label=None):\n","        '''from a file name and a path, returns a patient to whom gap filling has been applied\n","        Args : \n","            - filename : str -> name of the csv file\n","            - path : str -> path to go to thr file/\n","            - label : str -> patient's label\n","        Returns : \n","            - Patient object\n","        '''\n","        df = pd.read_csv(f\"{path}{filename}\", encoding=\"ISO-8859-1\")\n","        return cls(filename, df.drop(\"Unnamed: 0\",axis=1), label).gap_filling()\n","    \n","    @property\n","    def bloc(self):\n","        listname = self.name.split(\"_\") \n","        return int(listname[1])\n","        \n","    @property\n","    def pouls(self):\n","        return (self.df[\"Pouls\"]).to_numpy(copy=True)\n","\n","    @property\n","    def spo2(self):\n","        return (self.df[\"SpO2\"]).to_numpy(copy=True)\n","\n","    @property\n","    def temp(self):\n","        return (self.df[\"Temperature\"]).to_numpy(copy=True)\n","\n","    @property\n","    def fr(self):\n","        return (self.df[\"FR\"]).to_numpy(copy=True)\n","\n","    @property\n","    def seconde(self):\n","        return (self.df[\"seconde\"]).to_numpy(copy=True)\n","\n","    @property\n","    def pression(self):\n","        return (self.df[\"Pression\"]).to_numpy(copy=True)\n","\n","    @property\n","    def duree(self):\n","        return self.seconde[-1]-self.seconde[0]\n","    \n","    def slice(self, begin, leng):\n","        '''returns the Dataframe of a patient within the chosen time span.\n","        Args : \n","            - begin : int -> begining of the window\n","            - leng : int -> length of the window\n","        Return :\n","            - Patient object\n","        '''\n","        df_sliced = self.df.iloc[begin:begin + leng] #check si ca fait une copie\n","        df_sliced.reset_index(inplace=True, drop=True)\n","        return Patient(self.name, df_sliced, self.label)\n","    \n","    def standard(self):\n","        '''returns the normalized Dataframe of a patient.\n","        Args : \n","\n","        Returns : \n","            - Patient object -> Patient whom DataFrame is reduced and centered\n","         '''\n","        df = self.df.copy()\n","        df = (df - df.mean()) / df.std()\n","        return Patient(self.name, df, self.label)\n","\n","    def center(self):\n","        '''returns the centered Dataframe of a patient.\n","        Args : \n","\n","        Return : \n","            - Patient object -> Patient whom DataFrame is centered. \n","        '''\n","        df = self.df.copy()\n","        df -= df.mean()\n","        return Patient(self.name, df, self.label)\n","    \n","    def  smoothing(self, outlier):\n","        '''smooths the Dataframe of a patient.\n","        Args : \n","            -outlier: bool -> remove the outliers in the dataframe if True\n","\n","        Return : \n","            - Patient object\n","        '''\n","        df_smoothed  = pd.concat(\n","            [\n","                new_series(self.df[col], outlier and self.bloc==2) \n","                for col in self.df.columns\n","            ], \n","            axis = 1\n","        )\n","        return type(self)(self.name, df_smoothed, self.label)\n","\n","    def  gap_filling(self):\n","        ''' interpolates missing values, except the NaN values at the beginning and at the end of the surgery.\n","        Args : \n","            \n","        Return : \n","            - Patient object -> whom DataFrame does not include any NaNs\n","        '''\n","        df_filled  = pd.concat(\n","            [\n","                new_series_gap_filling(self.df[col])\n","                for col in self.df.columns\n","            ], \n","            axis = 1\n","        )\n","        \n","        df_filled = df_filled[df_filled[\"Pouls\"].notna() & df_filled[\"SpO2\"].notna()].copy() #The linear interpolation let NaNs at the beginning \n","        #and at the end of the DataFrame, which are removed thanks to this line\n","        df_filled.reset_index(inplace = True) #reset the index of the DataFrame, otherwise the first idice could be different from zero\n","        return type(self)(self.name, df_filled, self.label)\n","    \n","    #Beginning of the features:\n","\n","    def coefsPouls1_Spo2_0(self,begin,end):\n","        \"\"\"\n","        Returns the correlation coefficient between the Very Low Frequency Spo2 wavelet [0] and the Low Pulse Frequency wavelet [1]\n","        Args:\n","            - Patient object\n","        Return:\n","            - int -> coefficient\n","        \"\"\"\n","        df = self.df.iloc[int(begin*60//5): int(end*60//5)]\n","\n","        coefs_pouls = pywt.wavedec(df['Pouls'], level = 3, wavelet = 'db4')\n","        coefs_Spo2 = pywt.wavedec(df['SpO2'], level = 3, wavelet = 'db4')\n","\n","        warnings.filterwarnings(\"ignore\")\n","        r, _ = sc.stats.pearsonr(coefs_pouls[1],coefs_Spo2[0]) # si la spo2 est constante on obtient un warning et un NaN, ce cas est traité dans clean\n","        warnings.resetwarnings()\n","        return r\n","    \n","    def coefsPouls0_Spo2_0(self,begin,end):\n","        \"\"\"\n","        Returns the correlation coefficient between the Very Low Frequency Spo2 wavelet [0] and the Low Frequency Pulse wavelet [0]\n","        Args:\n","            - Patient object\n","        Return:\n","            - int -> coefficient\n","        \"\"\"\n","        df = self.df.iloc[int(begin*60//5): int(end*60//5)]\n","\n","        coefs_pouls = pywt.wavedec(df['Pouls'], level = 3, wavelet = 'db4')\n","        coefs_Spo2 = pywt.wavedec(df['SpO2'], level = 3, wavelet = 'db4')\n","        \n","        warnings.filterwarnings(\"ignore\")\n","        r, _ = sc.stats.pearsonr(coefs_pouls[0],coefs_Spo2[0]) # si la spo2 est constante on obtient un warning et un NaN, ce cas est traité dans clean\n","        warnings.resetwarnings()\n","        return r\n","    \n","    def mcr_spo2_0(self,begin,end):\n","        \"\"\"Returns the mean crossing rate of the Pulse1 function of the patient, ie the second function resulting from his wavelet\n","        Args:\n","        \n","        Returns:\n","        int -> mean crossing rate\"\"\"\n","        spo2 = self.df['SpO2']\n","        spo2.iloc[int(begin*60//5): int(end*60//5)]\n","        coefs = pywt.wavedec(spo2, level = 3, wavelet= 'db4')\n","        spo2_0 = coefs[0]\n","\n","        #calcul du mcr - mean crossing rate\n","        spo2_0 -= np.nanmean(spo2_0)\n","        m = np.sum(np.diff(spo2_0) < 0)\n","        m /= len(spo2_0)\n","\n","        return m\n","\n","    def mcr_pouls_1(self,begin,end):\n","        \"\"\"Returns the mean crossing rate of the Pulse1 function of the patient, ie the first function resulting from his wavelet\n","        Args:\n","        \n","        Returns:\n","        int -> mean crossing rate\"\"\"\n","        pouls = self.df['Pouls']\n","        pouls.iloc[int(begin*60//5): int(end*60//5)]\n","        coefs = pywt.wavedec(pouls, level = 3, wavelet = 'db4')\n","        pouls1 = coefs[1]\n","\n","        #calcul du mcr - mean crossing rate\n","        pouls1 -= np.nanmean(pouls1)\n","        m = np.sum(np.diff(pouls1) < 0)\n","        m /= len(pouls1)\n","\n","        return m\n","\n","    def ondelettes_SpO2_Pouls(self,begin,end):\n","        \"\"\"Returns the number of times i for which there is a reaction of the Pulse to an action of the Spo2\n","        Args: \n","        - self\n","        Returns:\n","        - L : int\"\"\"\n","        df = self.df\n","        df = df.iloc[int(begin*60//5) : int(end*60//5)]\n","        Pouls= df['Pouls'].interpolate(method = 'slinear')\n","        Spo2 = df['SpO2'].interpolate(method = 'slinear')\n","\n","        mask1 = Pouls.notna()\n","        mask2 = Spo2.notna()\n","        mask3 = mask1 * mask2\n","        \n","        Pouls = Pouls[mask3]\n","        Spo2 = Spo2[mask3]\n","\n","        if not len(Pouls):\n","            return 0\n","        \n","        coefs_pouls = pywt.wavedec(Pouls, level = 2, wavelet= 'db4')\n","        coefs_Spo2 = pywt.wavedec(Spo2, level = 2, wavelet= 'db4')\n","\n","        Pouls_1 = coefs_pouls[2]\n","        SpO2_1 = coefs_Spo2[2]\n","\n","        L = 0\n","        Pouls_1 = pd.Series(Pouls_1)\n","        SpO2_1 = pd.Series(SpO2_1)\n","        for i in range(3,len(Pouls_1)-3):\n","            if np.abs(SpO2_1[i]) > SpO2_1.std()*2 and (np.abs(Pouls_1[i:i+5]) > Pouls_1.std()*2).any():\n","                L+=1\n","        return L\n","\n","        \n","    def energy_dwt(self, features_list, start=0, length=10, level=4, outlier = True):\n","        \"\"\"\n","       Calculates the energy on the detail coefficients of the\n","         multilevel Discrete Wavelet Transform.\n","         The size and position of the window are in parameters.\n","        Args:\n","        features_list -> str list, represents the patient's caracteristics features on which we decide to calculate this features.\n","        start : int -> beginning of the chosen window in minutes\n","        length : int -> length of the chosen window in minutes\n","        level : int -> number of transformations\n","\n","        Returns:\n","        -int -> value of the energy\n","        \n","        \"\"\"\n","        patient = self.smoothing(outlier)\n","        data_pouls = patient.pouls[~np.isnan(patient.pouls) | ~np.isnan(patient.spo2)]\n","        \n","        start, length = int(start*60/5), int(length*60/5)\n","        waves = pywt.wavedec(data_pouls[start: start+length], 'db4', 'symmetric', level=level)\n","        \n","        energy = [\n","            np.nansum(np.abs(waves[lev]))/len(waves[lev])\n","            for lev in range(1,level+1)\n","        ]\n","        \n","        dict_wav = {\n","                \"energy_1\" : energy[3], \n","                \"energy_2\" : energy[2], \n","                \"energy_3\" : energy[1], \n","                \"energy_4\" : energy[0]\n","        }\n","        \n","        return { \n","            key: value \n","            for key,value in dict_wav.items() \n","            if key in features_list\n","        }\n","\n","\n","    def moment(patient, recordstype, order=1, scaled=False, reduit=False):\n","        \"\"\"\n","        Computes the 1st, 2nd, 3rd or 4th moment of a series, which can also be scaled and/or centered.\n","        \n","        Most relevant moments :\n","        - Coefficient d’asymétrie : order=3, center=True, scale=True\n","        - Non - normalized kurtosis : order=4, center=True, scale=True\n","        \n","        Args:\n","        -patient : Patient\n","        -ecordstype : string\n","        -order : int, optional\n","        -center : bool, optional\n","        -scale : bool, optional\n","\n","        Returns:\n","        -int -> value of the moment\n","        \n","        \"\"\"\n","        tab=patient.df[recordstype].to_numpy()\n","        tab = tab[~np.isnan(tab)] #delete the  NaNs\n","\n","        if center:\n","            tab -= np.mean(tab)\n","        \n","        if scale:\n","            warnings.filterwarnings(\"ignore\")\n","            tab /= np.std(tab) # if the spo2 is constant we get a warning and a NaN, this case is treated in clean\n","            warnings.resetwarnings()\n","        \n","        return np.sum(tab ** order) / len(tab)\n","    \n","    def corr_P_S_dwt(self, start=0, length=20, level=3):\n","        \"\"\"\n","        Function that tests whether the coefficients of the details of a DWT level\n","         for pulse rate and SpO2 are higher than their respective std.        \n","        Args :\n","\n","        -start : int -> beginning of the window in minutes\n","        -length : int -> length of the window in minutes\n","        -level : int -> number of trabsformed\n","\n","        Returns:\n","        -float\n","        \n","        \"\"\"\n","        kP, kS = .5, .5  # coeff std Pouls, SpO2\n","        \n","        start, length = int(start*60/5), int(length*60/5)\n","        \n","        wavesP = pywt.wavedec(self.df['Pouls'][start:start+length], 'db4', 'symmetric', level = level)\n","        wavesS = pywt.wavedec(self.df['SpO2'][start:start+length], 'db4', 'symmetric', level = level)\n","        \n","        stdP, stdS = kP * np.nanstd(wavesP[1]), kS * np.nanstd(wavesS[1])\n","\n","        return np.nansum((np.abs(wavesP[1]) < stdP) & (np.abs(wavesS[1]) > stdS))/len(wavesP[1])\n","\n","    def mean(patient, recordstype):\n","        return patient.df[recordstype].mean()\n","    \n","    def std(patient, recordstype):\n","        return patient.df[recordstype].std()\n","    \n","    def min(patient, recordstype):\n","        return patient.df[recordstype].min()\n","    \n","    def max(patient, recordstype):\n","        return patient.df[recordstype].max()\n","    \n","    def first_quartile(patient, recordstype):\n","        return patient.df[recordstype].quantile(0.25)\n","    \n","    def median(patient, recordstype):\n","        return patient.df[recordstype].quantile(0.5)\n","    \n","    def third_quartile(patient, recordstype):\n","        return patient.df[recordstype].quantile(0.75)\n","        \n","    def fourier(self, features_list, nperseg, begin, end, outlier=True) :\n","        \n","        \"\"\"\n","        Calculate 7 features:\n","             - integrations freq + abs time (X (f)) for the pulse then the SpO2,\n","                 - correlation coefficient between integration / freq of abs (X (f)) between Pulse and SpO2\n","                 - list of corr coefficients between certain X (f) of Pulse and SpO2\n","        ---Parameters---\n","        self = patient smoothed \n","        nperseg = int, window of stft in number of points (50 in general) \n","        begin, end = int, chosen temporal window in number of points\n","        outlier = bool, if True, remove the outliers\n","        \n","        ---Returns---\n","        pw_pouls_abs = float\n","        pw_SpO2_abs = float\n","        coeff_pw_abs = float\n","        coeff_freq = list, dtype = float, len(list) = 4 \n","        \"\"\"\n","        patient = self.smoothing(outlier).standard()\n","        data_pouls = patient.pouls[~np.isnan(patient.pouls) | ~np.isnan(patient.spo2)]\n","        data_SpO2 = patient.spo2[~np.isnan(patient.spo2) | ~np.isnan(patient.pouls)]\n","\n","        fp, tp, spec_p = sg.stft(\n","            data_pouls[begin : end],\n","            samplerate,\n","            'blackman',\n","            nperseg = nperseg\n","        )\n","\n","        fs, ts, spec_s = sg.stft(\n","            data_SpO2[begin : end],\n","            samplerate,\n","            'blackman',\n","            nperseg = nperseg\n","        )\n","        \n","        df_fft = fp[1] - fp[0]    \n","        pw_t_pouls_abs = [\n","            np.sum(np.abs(fft_t)) * df_fft \n","            for fft_t in spec_p.T\n","        ]\n","\n","        pw_t_SpO2_abs = [\n","            np.sum(np.abs(fft_t)) * df_fft \n","            for fft_t in spec_s.T\n","        ]\n","\n","        dt = tp[1] - tp[0]\n","        pw_pouls_abs = sum(pw_t_pouls_abs) * dt\n","        pw_SpO2_abs = sum(pw_t_SpO2_abs) * dt\n","        \n","        coeff_pw_abs = np.corrcoef(pw_t_pouls_abs, pw_t_SpO2_abs)[0,1]\n","\n","        coeff_freq = [\n","            np.corrcoef(np.abs(spec_p[freq]), np.abs(spec_s[freq]))[0,1]\n","            for freq in ([6,13,15])\n","        ]\n","        \n","        dict_fourier= {\n","            \"pw_pouls_abs\" : pw_pouls_abs, \n","            \"pw_SpO2_abs\" : pw_SpO2_abs, \n","            \"coeff_pw_abs\" : coeff_pw_abs, \n","            \"coeff_freq1\" : coeff_freq[0], \n","            \"coeff_freq2\" : coeff_freq[1], \n","            \"coeff_freq3\" : coeff_freq[2] \n","        }\n","        return { \n","            key: value \n","            for key,value in dict_fourier.items() \n","            if key in features_list\n","        }\n","    \n","    def pca_error(self,pca, begin=120, length=180):\n","        return float(\n","            compute_transform_error1(\n","                pca,\n","                [self.standard().slice(begin,length).pouls]\n","            )\n","        )\n","\n","    \n","\n","\n","#method which gather the features :\n","def get_features(patient, parameters):\n","    ''' allows access to the dataframe of a patient's features\n","    Args : \n","        - parameters : dict -> clé : features'name ; valeur :dictionary containing the name of the parameters of the associated method in keys and their values in value \n","    Return : \n","        - df_features : pd.DataFrame\n","    '''\n","    function_mapping = {\n","        \"mean_pouls\": patient.mean,\n","        \"mean_SpO2\": patient.mean,\n","        \"mean_FR\": patient.mean, \n","        \"mean_pression\": patient.mean, \n","        \"mean_temperature\": patient.mean,\n","        \"std_pouls\": patient.std,\n","        \"std_SpO2\": patient.std,\n","        \"std_FR\": patient.std, \n","        \"std_pression\": patient.std, \n","        \"std_temperature\": patient.std,\n","        \"min_pouls\": patient.min,\n","        \"min_SpO2\": patient.min,\n","        \"min_FR\": patient.min, \n","        \"min_pression\": patient.min, \n","        \"min_temperature\": patient.min,\n","        \"max_pouls\": patient.max,\n","        \"max_SpO2\": patient.max,\n","        \"max_FR\": patient.max, \n","        \"max_pression\": patient.max, \n","        \"max_temperature\": patient.max,\n","        \"median_pouls\": patient.median,\n","        \"median_SpO2\": patient.median,\n","        \"median_FR\": patient.median, \n","        \"median_pression\": patient.median, \n","        \"median_temperature\": patient.median,\n","        \"first_quartile_pouls\": patient.first_quartile,\n","        \"first_quartile_SpO2\": patient.first_quartile,\n","        \"first_quartile_FR\": patient.first_quartile, \n","        \"first_quartile_pression\": patient.first_quartile, \n","        \"first_quartile_temperature\": patient.first_quartile,\n","        \"third_quartile_pouls\": patient.third_quartile,\n","        \"third_quartile_SpO2\": patient.third_quartile,\n","        \"third_quartile_FR\": patient.third_quartile, \n","        \"third_quartile_pression\": patient.third_quartile, \n","        \"third_quartile_temperature\": patient.third_quartile,\n","        \"moment3_SpO2\":patient.moment,\n","        \"moment3_Pouls\":patient.moment,\n","        \"moment4_SpO2\":patient.moment,\n","        \"moment4_Pouls\":patient.moment,\n","        \"fourier\":patient.fourier,\n","        \"pca\": patient.pca_error, \n","        \"wavelet_corr_spo2_0_pouls_1\": patient.coefsPouls1_Spo2_0, \n","        \"wavelet_corr_spo2_0_pouls_0\": patient.coefsPouls0_Spo2_0, \n","        \"energy_dwt\" : patient.energy_dwt, \n","        \"corr_P_S_dwt\" : patient.corr_P_S_dwt, \n","        \"mcr_pouls_1\" : patient.mcr_pouls_1, \n","        \"mcr_spo2_0\" :patient.mcr_spo2_0, \n","        \"ondelettes_SpO2_Pouls\" : patient.ondelettes_SpO2_Pouls\n","    }\n","    \n","    df_features = pd.DataFrame([patient.name], columns = ['name'] )\n","    df_features['label'] = patient.label\n","    \n","    for feature in parameters.keys():\n","        if feature == \"fourier\":\n","            dict_fourier = function_mapping[feature](**parameters[feature])\n","            for key, value in dict_fourier.items():\n","                df_features[key] = value\n","        elif feature == \"energy_dwt\":\n","            dict_wav = function_mapping[feature](**parameters[feature])\n","            for key, value in dict_wav.items():\n","                df_features[key] = value\n","        else: \n","            df_features[feature] = [function_mapping[feature](**parameters[feature])]\n","    \n","    return df_features\n"]},{"cell_type":"markdown","metadata":{"id":"EpkqdDy2ThJL"},"source":["## PatientsList Class"]},{"cell_type":"markdown","metadata":{"id":"qvLNr28xThJL"},"source":["This class groups together patients and simplifies the massive generation of features.\n","A Patientlist object only has one attribute, which is a list of Patients objects.\n","The idea of this class is to apply the method of the Patient class directly to a group of patient."]},{"cell_type":"markdown","metadata":{"id":"ZmIuILoAThJL"},"source":["### Getting a list of patients\n","The class method from_folder transforms the csv files of patients (each file must correspond to only one operation) contained in a folder in a Patientlist object. The method called clean (described below) is applied on this list, so we don't have any issue with indexses getting out of range or NaNs in the columns after we made the Patientlist object."]},{"cell_type":"markdown","metadata":{"id":"bgogMWBYThJM"},"source":["### Making the class easier tu use\n","- magic method len : enables to access the len of a Patientlist object as if it was a classic list\n","- magic method iter : makes the Patientlist objects iterables."]},{"cell_type":"markdown","metadata":{"id":"RdZtPNfnThJM"},"source":["### Cleaning the list\n","method clean : makes a new Patientlist object by selecting only patients where saturation and pulse columns are complete and  the duration is long enough to be cut on a certain window."]},{"cell_type":"markdown","metadata":{"id":"kql-G_KWThJM"},"source":["### Apply Patient class methods\n","The four following methods have been implemented to apply the methods relative to the Patient class to a Patientlist object.\n","- method slice : slices the patient's data for each patient in the list.\n","- method standard : standardizes the patient's data for each patient in the list. \n","- method center: centers the patient's data for each patient in the list.\n","- method smoothing : smooths the patient's data for each patient in the list.\n","\n","this is made possible by the following method: \n","- method apply_to_list_patient : this method allows for applying a function relative to a patient to all of the \n","patients composing  a Patientlist object"]},{"cell_type":"markdown","metadata":{"id":"tNXJxp6GThJN"},"source":["### Preparing a train list\n","The 2 following methods select a certain part of the patients:\n","- method bloc_selection : enables to select only the patients that have been operated in a chosen bloc in a new Patientlist object.\n","- method label_selection :  enables to select only the patients that have received a certain label in a new Patientlist object.\n","The next two split a list into two sets of patients: the first one could be the training set and the second one the testing set. This comes in useful to test a new classifier.\n","- method split_training : split a Patientlist object in two : one Patientlist corresponding to the training set, with which we will train our classifier, and one Patientlist corresponding to the testing set, with wich classifiers' performances will be evaluated. It is essential\n","to do so because we can't test an algorithm on a set with which he has already been trained; this would introduce a huge bias.\n","The proportion of labels in the two lists are the same as in the data.\n","- method split_homogene: similar to split_training, but we make sure that the proportion of labels in the two lists are the same as in the data.\n","\n","\n","- method label : returns a DataFrame with the name of the patients composing a Patientlist and their label. It is necessary because the classifier needs to have access to the label of patients when they train, and also when we test them.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IMQVEH1AThJN"},"source":["### Getting the features: \n","The get_features_list_patient method writes a DataFrame in which each column corresponds to a feature, and each line corresponds to a patient\n","present in the Patientlist object. Calculating the features is pretty long, so it spares a lot of time to store them in a DataFrame for the rest \n","of the process. Moreover, the access to the features is made easier by using pandas DataFrames.\n"]},{"cell_type":"markdown","metadata":{"id":"WF-c5rLBThJO"},"source":["### PCA\n","The train_pca method is apart because, as said before, the pca is a classifier in itself and has to be trained with a training set. We used it as a feature because we thought it was a good point to see if the data we had was easy to summarize or not. This method trains the pca algorithm. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nbar2pZBThJO"},"outputs":[],"source":["class PatientsList:\n","    \"\"\"Represents a list of patients\n","    \"\"\"\n","    def __init__(self, patient_list: List[Patient]):\n","        self.patientslist = patient_list\n","\n","    @classmethod\n","    def from_folder(cls, path_to_folder, label=True):\n","        \"\"\"Returns a Patientslist instance built from a folder contaning data.\n","        Args:\n","            -path_to_folder : string\n","        Returns :\n","            -PatientsList object\n","        \"\"\"\n","\n","        patient_list = []\n","        if label:\n","            for foldername in os.listdir(path_to_folder):\n","                for filename in os.listdir(f\"{path_to_folder}{foldername}\"):\n","                    patient = Patient.from_file(\n","                        filename, f\"{path_to_folder}{foldername}/\", foldername\n","                    )\n","                    patient_list.append(patient)\n","        else: \n","            for filename in os.listdir(path_to_folder):\n","                    patient = Patient.from_file(\n","                        filename, f\"{path_to_folder}/\"\n","                    )\n","                    patient_list.append(patient)\n","        return cls(patient_list).clean()\n","\n","    def __len__(self):\n","        return len(self.patientslist)\n","\n","    def __iter__(self):\n","        return iter(self.patientslist)\n","\n","    def clean(self, begin=120, length=180):\n","        \"\"\"Slices all of the dataframes of the list of patients from begin to begin + length.\n","        Args:\n","            -begin: int \n","            -length : int \n","        Returns :\n","            -Patientslist object\n","        \"\"\"\n","\n","        cleaned_list = [ \n","            patient \n","            for patient in self.patientslist \n","            if (\n","                patient.df[\"Pouls\"].notna().all() \n","                and patient.df[\"SpO2\"].notna().all() \n","                and len(patient.pouls)>begin+length\n","            )\n","        ]\n","        return PatientsList(cleaned_list)\n","\n","    def slice(self, begin, length, to_the_end=False):\n","        \"\"\"Smooths every Dataframe of the list of patients.\n","        Args:\n","\n","        Return:\n","            -PatientsList object\n","        \"\"\"\n","        if to_the_end:\n","            slicedlist = [\n","            patient.slice(begin, len(patient.df)-begin)\n","            for patient in self.patientslist\n","            if (len(patient.df) >= begin)\n","        ]\n","        else:\n","            slicedlist = [\n","                patient.slice(begin, length)\n","                for patient in self.patientslist\n","                if (len(patient.df.iloc[begin:]) >= length)\n","            ]\n","        return PatientsList(slicedlist)\n","    \n","    def standard(self):\n","        \"\"\"Applies a function to every patient of the list of patients.\n","        Args:\n","            -function :callable\n","            -list -> list of the arguments of the function\n","        Returns:\n","            -PatientList object\n","        \"\"\"\n","\n","        standardedlist = [\n","            patient.standard()\n","            for patient in self.patientslist\n","        ]\n","        return PatientsList(standardedlist)\n","    \n","    def center(self):\n","        \"\"\"Returns the centered data of each patient of the list.\n","        Args :\n","            -k : int -> bloc choisi\n","        Returns:\n","            -PatientList\n","        \"\"\"\n","\n","        centeredlist = [\n","            patient.center()\n","            for patient in self.patientslist\n","        ]\n","        return PatientsList(centeredlist)\n","\n","    def smoothing(self, outlier=True):\n","        smoothedlist = [patient.smoothing(outlier) for patient in self.patientslist]\n","        return PatientsList(smoothedlist)\n","\n","    def apply_to_list_patient(self, fonction, args):\n","        appliedlist = [fonction(patient, *args) for patient in self.patientslist]\n","        return PatientsList(appliedlist)\n","\n","    def bloc_selection(self, k):\n","        \"\"\"Selects all the patient operated in the operating room number \"k\".\n","        Args :\n","            -k : int -> chosen operating room\n","        Returns:\n","            -PatientList\n","        \"\"\"\n","        patientlist = [\n","            self.patientslist[i]\n","            for i in range(len(self.patientslist))\n","            if self.patientslist[i].bloc == k\n","        ]\n","        return PatientsList(patientlist)\n","\n","    def label_selection(self, label):\n","        \"\"\"Selects all the patients labeled as \"label\".\n","        Args :\n","            -label : int -> bloc choisi\n","        Returns:\n","            -PatientList\n","        \"\"\"\n","\n","        patientlist = [\n","            self.patientslist[i]\n","            for i in range(len(self.patientslist))\n","            if self.patientslist[i].label == label\n","        ]\n","        return PatientsList(patientlist)\n","\n","    \n","    def split_training(self, ratio_kept):\n","        \"\"\"Splits a list of patients into a train list and a test list.\n","        Args : \n","            -ratio_kept : int -> ratio between the length of the train list and the test list.\n","        Returns :\n","            -Patientlist object tuple\n","        \"\"\"\n","\n","        list_to_split = sample(self.patientslist, len(self))\n","        n = int(ratio_kept * len(self.patientslist))\n","        return PatientsList(list_to_split[:n]), PatientsList(list_to_split[n:])\n","    \n","    def split_homogene(self, ratio_kept, labels_choisis):\n","        \"\"\"Splits a list of patients into a train list and a test list where the proportion of labels are consistent with that of the cohort.\n","\n","        Args : \n","            -ratio_kept : int -> ratio between the length of the train list and the test list.\n","            -labels_choisis : list -> list of the labels that will appear in the test list\n","        Returns:\n","            - tuple of Patientlist objects\n","        \"\"\" \n","\n","        n = int(ratio_kept * len(self.patientslist))\n","        \n","        list_by_labels = [\n","            self.label_selection(label).split_training(ratio_kept)\n","            for label in labels_choisis\n","        ]\n","        list_by_labels_train = [el[0] for el in list_by_labels]\n","        list_by_labels_test = [el[1] for el in list_by_labels]\n","        list_train = list(itertools.chain(*list_by_labels_train))\n","        list_test = list(itertools.chain(*list_by_labels_test))\n","        \n","        shuffle(list_train)\n","        shuffle(list_test)\n","        \n","        return PatientsList(list_train), PatientsList(list_test)\n","        \n","        \n","\n","    def label(self):\n","        \"\"\"Returns a pandas series containing the label of each patient.\n","        Args : \n","        \n","        Returns:\n","            -Pandas.DataFrame\n","        \"\"\" \n","\n","        df = pd.DataFrame(columns=[\"name\",\"label\"])\n","        for patient in self.patientslist:\n","            df = df.append({\"name\" : patient.name, \"label\" : patient.label}, ignore_index=True)\n","        df = df.set_index(\"name\")\n","        return df\n","\n","    def get_features_list_patient(self, arguments):\n","        \"\"\"Returns a Dataframe containing all of the features of each patient.\n","        Args :\n","            -arguments : dict -> dictionary containing as keys the names of the chosen features and as values dictionaries, contaning as keys \n","            the names of the parameters of the features and as values the chosen values.\n","        Returns :\n","            -Pandas.DataFrame\n","        \"\"\"\n","\n","        df_features = pd.DataFrame()\n","        for patient in  (self.patientslist):\n","            df_features = df_features.append(get_features(patient, arguments ), ignore_index = True  )\n","        df_features.set_index(\"name\", inplace = True)\n","        for col in df_features.columns[2:]:\n","            df_features.loc[df_features[col].isna(),col] = df_features[col].mean() # on traite les features utilisant la correlation et la division par l'écart type qui sont nan si la spo2 est constante\n","        return df_features\n","\n","    def train_pca(self, n_components=20,  label=\"clean\", begin=120, length=180):\n","        '''Computes the PCA from a test group containing patients labeled as \"clean\".\n","        Args :\n","            -n_components : int -> number of components.\n","            -label : string -> label of the test group.\n","            -begin : int -> beginning of the window on which the PCA will work.\n","            -length : int -> length of the window.\n","        Returns:\n","            -new_pca : numpyarray\n","\n","        '''\n","        clean_train = [\n","            patient.pouls\n","            for patient in self.label_selection(label).standard().slice(begin, length).patientslist \n","        ]\n","        new_pca = decomposition.PCA(n_components)\n","        new_pca.fit(clean_train)\n","        return new_pca\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GFPrCky1ThJP"},"source":["### Getting Features"]},{"cell_type":"markdown","metadata":{"id":"BGSETK8KThJQ"},"source":["The get_feature method takes a dictionnary as argument, with as keys the names of the features and as values dictionnaries containing as keys the names of the arguments used by the corresponding feature method, and as values their values.\n","\n","A feature can easily be added to the proccess (in this dictionnary, in the get_feature method and in the Patient Class)."]},{"cell_type":"markdown","metadata":{"id":"TPwtJvTyThJQ"},"source":["<a id=\"all_features\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jdhi4BpKThJQ"},"outputs":[],"source":["feature_dict_all = {\"fourier\" : \n","              {\"features_list\" : [\"pw_pouls_abs\",\"pw_SpO2_abs\",\"coeff_pw_abs\",\"coeff_freq1\",\"coeff_freq2\",\"coeff_freq3\"], \n","                \"nperseg\" : 50,\n","                \"begin\" : 0,\n","                \"end\" : 270},\n","                \"energy_dwt\" : \n","              {\"features_list\" : [\"energy_1\",\"energy_2\",\"energy_3\",\"energy_4\"], \"start\" : 0, \"length\" : 32.5},\n","              \"ondelettes_SpO2_Pouls\": {\"begin\" : 0, \"end\": 20},\n","              \"moment3_Pouls\" :\n","              {'recordstype' : 'Pouls', 'order' : 3 , 'centre' : True, 'reduit' : True },\n","              \"moment3_SpO2\" :\n","              {'recordstype' : 'SpO2', 'order' : 3 , 'centre' : True, 'reduit' : True },\n","              \"moment4_Pouls\" :\n","              {'recordstype' : 'Pouls', 'order' : 4 , 'centre' : True, 'reduit' : True },\n","              \"moment4_SpO2\" : \n","              {'recordstype' : 'SpO2', 'order' : 4 , 'centre' : True, 'reduit' : True },\n","              \"mean_pouls\" : \n","              {'recordstype' :'Pouls'},\n","              \"mean_SpO2\" : \n","              {'recordstype' :'SpO2'},\n","              \"std_pouls\" :\n","              {'recordstype' : 'Pouls'},\n","              \"std_SpO2\" :\n","              {'recordstype' : 'SpO2'},\n","              \"min_pouls\" :\n","              {'recordstype' : 'Pouls'},\n","              \"min_SpO2\":\n","              {'recordstype' : 'SpO2'},\n","              \"max_pouls\":\n","              {'recordstype' : 'Pouls'},\n","              \"max_SpO2\":\n","              {'recordstype' : 'SpO2'},\n","              \"first_quartile_pouls\":\n","              {'recordstype' : 'Pouls'},\n","              \"first_quartile_SpO2\":\n","              {'recordstype' : 'SpO2'},\n","              \"median_pouls\":\n","              {'recordstype' : 'Pouls'},\n","              \"median_SpO2\":\n","              {'recordstype' : 'SpO2'},\n","              \"third_quartile_pouls\":\n","              {'recordstype' : 'Pouls'},\n","              \"third_quartile_SpO2\":\n","              {'recordstype' : 'SpO2'},\n","              \"wavelet_corr_spo2_0_pouls_1\" :\n","              {\"begin\" : 0, \"end\": 32.5},\n","              \"wavelet_corr_spo2_0_pouls_0\": \n","              {\"begin\" : 0, \"end\": 32.5}, \n","              \"corr_P_S_dwt\" : \n","              {\"start\" : 0, \"length\" : 32.5}, \n","              \"mcr_pouls_1\" :\n","              {\"begin\" : 0, \"end\": 32.5}, \n","              \"mcr_spo2_0\" :\n","              {\"begin\" : 0, \"end\": 32.5}\n","\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"ISlIdL-uThJR"},"source":["Example of result of the get_feature_list_patients method:\n","<img src=\"features.png\" width=80%></img>"]},{"cell_type":"markdown","metadata":{"id":"0XHD94EVThJR"},"source":["It is time to implement our final algorithm, in order to predict whether our patient will suffer from a heart attack. The idea is to make a first statement after 20 or 30 minutes of surgery, considering that something in this part of the data could warn us about an attack.  \n","\n","During the first part of the surgery (beginning of anaesthesia), the patient is very unstable and some features are not compatible with those variations. So we chose to cut (slicing method) this part for every patient before calculating our features, and because the goal here is not to predict any heart attack during this part of the surgery."]},{"cell_type":"markdown","metadata":{"id":"BwTTEE74ThJR"},"source":["## Prediction\n"]},{"cell_type":"markdown","metadata":{"id":"e8trKrUNThJS"},"source":["#### Features"]},{"cell_type":"markdown","metadata":{"id":"TWGQ92HAThJS"},"source":["Chosen features are defined below. [(see dictionnary with all features here)](#all_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USFXnai5ThJS"},"outputs":[],"source":["feature_dict_final = {\"fourier\" : \n","              {\"features_list\" : [\"pw_pouls_abs\"], \n","                \"nperseg\" : 50,\n","                \"begin\" : 0,\n","                \"end\" : 270},\n","              \"mean_pouls\" : \n","              {'recordstype' :'Pouls'},\n","              \"mean_SpO2\" : \n","              {'recordstype' :'SpO2'},\n","              \"std_pouls\" :\n","              {'recordstype' : 'Pouls'},\n","              \"std_SpO2\" :\n","              {'recordstype' : 'SpO2'}\n","\n","}\n","used_features = [\"pw_pouls_abs\", \"mean_SpO2\", \"mean_pouls\", \"std_SpO2\", \"std_pouls\"]\n"]},{"cell_type":"markdown","metadata":{"id":"gM_scaY2ThJS"},"source":["### Classifier and training"]},{"cell_type":"markdown","metadata":{"id":"BdPgNCCHThJT"},"source":["To use this cell, a folder containing folders named by labels: clean, attack (and anomaly if you want) has to be created.\n","Any classifier can be used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKjmwnA5ThJT","outputId":"ff9d277f-e0ef-4582-9710-aec426f79bdf"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'train/'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/53/knyk_r6x3tgb66xwzpl33bv40000gn/T/ipykernel_29695/3406485484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpatients_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatientsList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatients_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_the_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_list_patient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabel_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatients_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/53/knyk_r6x3tgb66xwzpl33bv40000gn/T/ipykernel_29695/428028716.py\u001b[0m in \u001b[0;36mfrom_folder\u001b[0;34m(cls, path_to_folder, label)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpatient_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfoldername\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path_to_folder}{foldername}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     patient = Patient.from_file(\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/'"]}],"source":["\n","classifier = RandomForestClassifier(\n","    n_estimators=100,\n","    max_depth=5,\n","    class_weight='balanced'\n",")\n","\n","patients_train = PatientsList.from_folder(\"train/\")\n","df_train = patients_train.slice(150, -1, to_the_end=True).get_features_list_patient(feature_dict_final).loc[:, used_features]\n","label_train = patients_train.label()\n","\n","\n","classifier.fit(df_train, label_train['label'])\n","\n","\n","#this cell might run for several minutes"]},{"cell_type":"markdown","metadata":{"id":"9-gfjPBBThJR"},"source":["### Features and Classifier choice\n","\n","We tested a lot of combinations of features with several classifiers (with different parameters) like kNNClassifier or MLPClassifier. We here use the RandomForestClassifier, which gave us the best results (accuracy and recall) combined with the following set of features (see used_features and features_dict_final). It is also a classifier that gives a lot of informations on the way he makes his decisions, which is essential for anesthetists."]},{"cell_type":"markdown","metadata":{"id":"53arXp54ThJV"},"source":["### Prediction function\n","After training the RandomForestClassifier, we just have to give the path to the csv files with the raw data (the function automatically splits the patients if needed). The function returns a dataframe with the predicted labels and the name of the patient, such as the dataframe shown below.\n"]},{"cell_type":"markdown","metadata":{"id":"040bsGsDThJV"},"source":["<img src=\"dataframe_prediction.png\">"]},{"cell_type":"markdown","metadata":{"id":"zmwpvBJcThJW"},"source":["The process takes 7 minutes for 400 patients (spliting + getting the features + predicting)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNFlQYL-ThJW"},"outputs":[],"source":["def patientsprediction(foldername):\n","    processing(foldername)\n","    patientstopredict = PatientsList.from_folder(\"patients/\",label=False)\n","    df_features = patientstopredict.get_features_list_patient(feature_dict_final)\n","    df_test = df_features.loc[:, used_features]\n","    \n","    prediction = classifier.predict(df_test)\n","    \n","    return pd.concat(\n","        [\n","            pd.Series(df_features.index, name=\"name\"),\n","            pd.Series(prediction, name=\"prediciton\")\n","        ],\n","        axis = 1\n","    )"]},{"cell_type":"markdown","metadata":{"id":"EbBwE4SEThJX"},"source":["This last function allows for evaluation of the prediction of the previous classifier and returns the confusion matrix. It takes as argument the path to the folder containing your labelled data (containing folders named by label)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdqjzOzjThJX"},"outputs":[],"source":["def comparaison_label_prediction(foldername):\n","    patientstopredict = PatientsList.from_folder(foldername)\n","    df_features = patientstopredict.get_features_list_patient(feature_dict_final)\n","    df_test = df_features.loc[:, used_features]\n","    prediction = classifier.predict(df_test)\n","    labels = patientstopredict.label()\n","    \n","    return metrics.confusion_matrix(\n","        labels.to_numpy(),\n","        prediction,\n","        labels = [\"clean\", \"attack\"]\n","    )"]}],"metadata":{"interpreter":{"hash":"569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"provenance":[{"file_id":"1ZTHvMaviatLhocboMXKgaYJWq16C49Nv","timestamp":1666031327133}],"collapsed_sections":["1ULyRJcHThIw","oABgUascThIx","8tODnR1DThIy","UNqqttjHThI1","Uaq5tF-jThI9","vOL2Qq0NThJB","aYR5Qk2mThJC","MriEFlhCThJE","c_Owovp0ThJF","v4uRwLeuThJF","GoQqhfNQThJG","NHm4_kVIThJG","ZmIuILoAThJL","bgogMWBYThJM","RdZtPNfnThJM","kql-G_KWThJM","tNXJxp6GThJN","IMQVEH1AThJN","WF-c5rLBThJO","GFPrCky1ThJP","9-gfjPBBThJR","e8trKrUNThJS","gM_scaY2ThJS","53arXp54ThJV"]}},"nbformat":4,"nbformat_minor":0}